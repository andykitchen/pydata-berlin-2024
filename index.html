<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>A Meating of Minds — PyData Berlin 2024 </title>

    <link rel="stylesheet" href="dist/reset.css">
    <link rel="stylesheet" href="dist/reveal.css">
    <link rel="stylesheet" href="dist/theme/black.css">

    <!-- Theme used for syntax highlighted code -->
    <link rel="stylesheet" href="plugin/highlight/monokai.css">
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section>
          <section>
            <h1>A Meating of Minds</h1>
          </section>
          <section>
            AI research is the strange science that seeks to define
            what it studies while it studies what it defines.
          </section>
          <section>
            Too Ambitious
          </section>
        </section>
        <section>
          NeuroAI
        </section>
        <section>
          <section>
            Information Theory (Claude Shannon)
            Kolmogorov Complexity (Andrey Kolmogorov)
            Algorithmic Information Theory (Ray Solomonoff)
          </section>
          <section>
            Solomonoff Induction (Ray Solomonoff)
            AIXI
            (Marcus Hutter)
          </section>
          <section>
            Mathematical Theory of Beauty /
            Artificial Curiosity
            (Jurgen Schmidhuber)
          </section>
          <section>
            Free Energy Principle /
            Active Inference
            (Karl Friston)
          </section>
          <section>
            <h2>Autopoiesis</h2>
            <p>The capacity to constantly self-realise</p>
          </section>
        </section>
        <section>
          <section>
            <q>I think I think, therefore I think I am.</q><br>— Les Kitchen
          </section>
          <section>
            <q>Consciousness is a pre-scientific term [...] When we get down to doing science, it’s just a useless concept.</q><br>— Hinton
          </section>
          <section>
            Consciousness has no constructive context
          </section>
        </section>
        <section>
          <section>
            <h2>An uphill battle</h2>
            <p>Gradient descent is the worst form of learning algorithm, except all those that have been tried so far...</p>
          </section>
        </section>
        <section>
          <section>
            <h2>Quasi-grounding</h2>
            <p>Asking if an LLM “understands” language is like asking if a match understands fire.</p>
          </section>
          <section>
            Playing the language game
          </section>
        </section>
        <section>
          <section>
            Curiosity
          </section>
          <section>
            Compression Increase (Schmidhuber)
          </section>
          <section>
            Path Space Occupancy
          </section>
        </section>
        <section>
          
        </section>
        <section>
          <section>
            NeuroAI
          </section>
          <section>
          </section>
          <section>
          </section>
        </section>
        <section>
          <section>
            <h2>High ceilings on the Chinese Room</h2>
            <p>Still no gardener</p>
          </section>
          <section>
            Thought experiments from philosophy
            are becoming real experiments.
          </section>
          <section>
          </section>
        </section>
        <section>
          <section>
            Consciousness = Embodiment + Autopoiesis + Intrinsic Learning + World Models + Metacognition + Metalearning + ...
          </section>
          <section>
            What's Next?
          </section>
          <section>
            <ul>
              <li>Intrinsic Learning
              <li>Intrinsic Motivation
              <li>Meta Learning
            </ul>
          </section>
        </section>
        <section>
          <section>
            <h4>Bibliography (such as it is)</h4>
            <ul>
              <li><a href="https://arxiv.org/abs/2405.04540">Is artificial consciousness achievable? Lessons from the human brain</a>
              <li><a href="https://www.nature.com/articles/s41467-023-37180-x">Catalyzing next-generation Artificial Intelligence through NeuroAI</a>
              <li><a href="https://people.idsia.ch/~juergen/artificial-curiosity-since-1990.html">Artificial Curiosity & Creativity Since 1990-91</a>
              <li><a href="https://raysolomonoff.com/">Homepage of Ray Solomonoff</a>
              <li><a href="https://magazine.utoronto.ca/research-ideas/technology/getting-smarter-computer-science-professor-geoffrey-hinton-is-helping-to-build-a-new-generation-of-intelligent-machines/">Getting Smarter, Hinton Interview</a>
            </ul>
          </section>
          <section>
          </section>
          <section>
          </section>
        </section>
      </div>
    </div>

    <script src="dist/reveal.js"></script>
    <script src="plugin/notes/notes.js"></script>
    <script src="plugin/markdown/markdown.js"></script>
    <script src="plugin/highlight/highlight.js"></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,

        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
      });
    </script>
  </body>
</html>
